{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet \n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfFile, PdfPages\n",
    "from ctypes.wintypes import SIZE\n",
    "from astropy.timeseries import LombScargle\n",
    "from matplotlib.backends.backend_pdf import PdfFile, PdfPages\n",
    "import numpy as np\n",
    "from astropy.timeseries import LombScargle\n",
    "import matplotlib.transforms as transforms\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from scipy.signal import argrelextrema\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_depth(gcs,start,end): #這邊的start,end單位是no. of timeframe\n",
    "    endtime = end\n",
    "    df = pd.read_csv(gcs) \n",
    "    if end == \"end\":\n",
    "        end = len(df) \n",
    "    else:\n",
    "        end = end+10\n",
    "    df['Start_time'] = pd.to_numeric(df['Start_time'])\n",
    "    #df['end_time'] = pd.to_numeric(df['end_time'])\n",
    "    \n",
    "    words = []\n",
    "    for index, rows in df.loc[(df[\"Start_time\"]>=start) & (df[\"Start_time\"]<=(end))].iterrows():\n",
    "        words.append(rows[\"Words\"])\n",
    "    syn_counts = 0\n",
    "    num_of_hyponyms_below = 0\n",
    "    worddepths = []\n",
    "    for words_num in range(0, len(words)): #標定字\n",
    "        if len(wordnet.synsets(words[words_num])) > 0 :\n",
    "            syns1 = wordnet.synsets(words[words_num])\n",
    "            syns1_num = len(syns1)#這個字有幾個synset\n",
    "            syn_counts += syns1_num\n",
    "            \n",
    "            for synsnum in range(0,syns1_num):  #把每個synset的depth 都加上去\n",
    "                #synset_depth_sum+=syns1[synsnum].min_depth()\n",
    "                ### 用來算到lowest hyponyms的距離\n",
    "                threshhold = []\n",
    "                threshhold = syns1[synsnum].hyponyms()  \n",
    "                hyponyms_layer_count = 0\n",
    "                #print(threshhold)\n",
    "                #print(\"word:\",syns1[synsnum])\n",
    "                if threshhold != []:\n",
    "                    yesorno=True\n",
    "                else:\n",
    "                    yesorno = False\n",
    "                while_count  = 0\n",
    "                while yesorno:\n",
    "                    while_count +=1\n",
    "                    #print(\"進第\",while_count,\"層\")\n",
    "                    yesorno = False\n",
    "                    hyponyms_layer_count += 1\n",
    "                    new_hyponyms = []\n",
    "                    #startt = time.time()\n",
    "                    for syns in threshhold:\n",
    "                        #print(\"syns\",syns)\n",
    "                        #print(\"thresh\",threshhold)\n",
    "                        if syns is not []:\n",
    "                            yesorno = True \n",
    "                            #print(\"有hypo\",syns)\n",
    "                            new_hyponyms += syns.hyponyms()\n",
    "                            #print(new_hyponyms)       \n",
    "                     \n",
    "                    threshhold = []\n",
    "                    threshhold = new_hyponyms\n",
    "                    #print(\"the\",threshhold)\n",
    "                    new_hyponyms.clear()\n",
    "                    new_hyponyms = []\n",
    "               \n",
    "                if hyponyms_layer_count !=0:\n",
    "                    num_of_hyponyms_below += hyponyms_layer_count\n",
    "                else:\n",
    "                    num_of_hyponyms_below +=0\n",
    "                #print(hyponyms_layer_count)\n",
    "        else:\n",
    "            continue\n",
    "    print(num_of_hyponyms_below, syn_counts)\n",
    "    print(\"start:\",start,\"end:\",endtime, \", hyponyms_layer_count=\", (num_of_hyponyms_below/syn_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2262 2971\n",
      "start: 0 end: 200 , hyponyms_layer_count= 0.7613598115112756\n",
      "3104 3808\n",
      "start: 200 end: 480 , hyponyms_layer_count= 0.8151260504201681\n",
      "1772 2387\n",
      "start: 0 end: 150 , hyponyms_layer_count= 0.7423544197737746\n",
      "4378 6147\n",
      "start: 150 end: 480 , hyponyms_layer_count= 0.7122173417927444\n",
      "3870 4768\n",
      "start: 0 end: 300 , hyponyms_layer_count= 0.8116610738255033\n"
     ]
    }
   ],
   "source": [
    "i=13\n",
    "average_word_depth(f\"data/Text/0{i}(done).csv\",0,200)\n",
    "average_word_depth(f\"data/Text/0{i}(done).csv\",200,480)\n",
    "\n",
    "i=18\n",
    "average_word_depth(f\"data/Text/0{i}(done).csv\",0,150)\n",
    "average_word_depth(f\"data/Text/0{i}(done).csv\",150,480)\n",
    "\n",
    "i=11\n",
    "average_word_depth(f\"data/Text/0{i}(done).csv\",0,300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('matriculate.n.01'), Synset('student_teacher.n.01')]\n"
     ]
    }
   ],
   "source": [
    "syns1 = wordnet.synsets(\"college_student\")\n",
    "print(syns1[0].hyponyms())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('semantic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c54165d08fd550b20e5d70a45269718a12194b1a3ed2e8c4cf823acd6cf23912"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
