{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import speech\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(file_number):\n",
    "    \n",
    "\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'data/recordings/key.json'\n",
    "    speech_client = speech.SpeechClient()\n",
    "\n",
    "    # Example 1 & 2. Transcribe Local Media File \n",
    "    # File Size: < 10mbs, length < 1 minute\n",
    "    '''\n",
    "    config_wav = speech.RecognitionConfig(\n",
    "        sample_rate_hertz=44100,\n",
    "        enable_automatic_punctuation=True,\n",
    "        language_code='en-NG',\n",
    "        audio_channel_count=2,\n",
    "        enable_word_time_offsets=True\n",
    "    )\n",
    "    '''\n",
    "    # Example 3: Transcribing a long media file\n",
    "    media_uri = f'gs://speech_to_text1234/recordings/{file_number}.wav'\n",
    "    long_audi_wav = speech.RecognitionAudio(uri=media_uri)\n",
    "\n",
    "    config_wav_enhanced = speech.RecognitionConfig(\n",
    "        sample_rate_hertz=44100,\n",
    "        enable_automatic_punctuation=False,\n",
    "        language_code='en-US',\n",
    "        use_enhanced=True,\n",
    "        enable_word_time_offsets=True,\n",
    "        model= \"phone_call\"\n",
    "    )\n",
    "\n",
    "    operation = speech_client.long_running_recognize(\n",
    "        config=config_wav_enhanced,\n",
    "        audio=long_audi_wav\n",
    "    )\n",
    "    response = operation.result(timeout=480)\n",
    "    Number_words = 0\n",
    "    word_list = []\n",
    "    word_start_time = []\n",
    "    word_end_time = []\n",
    "    for result in response.results:\n",
    "        alternative = result.alternatives[0]\n",
    "    Number_words = 0\n",
    "    for result in response.results:\n",
    "            alternative = result.alternatives[0]\n",
    "            print(\"Transcript: {}\".format(alternative.transcript))\n",
    "            \n",
    "            for word_info in alternative.words:\n",
    "                word = word_info.word\n",
    "                start_time = word_info.start_time\n",
    "                end_time = word_info.end_time\n",
    "                word_list.append(word)\n",
    "                word_start_time.append(start_time.total_seconds())\n",
    "                word_end_time.append(end_time.total_seconds())\n",
    "                \"\"\"\n",
    "                print(\n",
    "                    f\"Num: {Number_words}, Word: {word}, start_time: {start_time.total_seconds()}, end_time: {end_time.total_seconds()}\"\n",
    "                )\n",
    "                \"\"\"\n",
    "                Number_words += 1\n",
    "    df = pd.DataFrame(list(zip(word_list,word_start_time,word_end_time)), columns = ['Words',\"Start_time\",\"End_time\"])\n",
    "    df.to_csv(f'data/Text/{file_number}.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 Invalid recognition 'config': bad encoding..",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\chang\\anaconda3\\envs\\Semantic_SBERT2\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:50\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     51\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\chang\\anaconda3\\envs\\Semantic_SBERT2\\lib\\site-packages\\grpc\\_channel.py:946\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    944\u001b[0m state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[0;32m    945\u001b[0m                               wait_for_ready, compression)\n\u001b[1;32m--> 946\u001b[0m \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\chang\\anaconda3\\envs\\Semantic_SBERT2\\lib\\site-packages\\grpc\\_channel.py:849\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 849\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"Invalid recognition 'config': bad encoding..\"\n\tdebug_error_string = \"{\"created\":\"@1659994551.920000000\",\"description\":\"Error received from peer ipv4:172.217.1.10:443\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1064,\"grpc_message\":\"Invalid recognition 'config': bad encoding..\",\"grpc_status\":3}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Python Projects\\Semantic_SBERT\\speech_to_text_automated.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Python%20Projects/Semantic_SBERT/speech_to_text_automated.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m8\u001b[39m,\u001b[39m22\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Python%20Projects/Semantic_SBERT/speech_to_text_automated.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     convert(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m00\u001b[39;49m\u001b[39m{\u001b[39;49;00mn\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Python Projects\\Semantic_SBERT\\speech_to_text_automated.ipynb Cell 3\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(file_number)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Python%20Projects/Semantic_SBERT/speech_to_text_automated.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m long_audi_wav \u001b[39m=\u001b[39m speech\u001b[39m.\u001b[39mRecognitionAudio(uri\u001b[39m=\u001b[39mmedia_uri)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Python%20Projects/Semantic_SBERT/speech_to_text_automated.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m config_wav_enhanced \u001b[39m=\u001b[39m speech\u001b[39m.\u001b[39mRecognitionConfig(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Python%20Projects/Semantic_SBERT/speech_to_text_automated.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     sample_rate_hertz\u001b[39m=\u001b[39m\u001b[39m44100\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Python%20Projects/Semantic_SBERT/speech_to_text_automated.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     enable_automatic_punctuation\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Python%20Projects/Semantic_SBERT/speech_to_text_automated.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     model\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mphone_call\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Python%20Projects/Semantic_SBERT/speech_to_text_automated.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Python%20Projects/Semantic_SBERT/speech_to_text_automated.ipynb#W2sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m operation \u001b[39m=\u001b[39m speech_client\u001b[39m.\u001b[39;49mlong_running_recognize(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Python%20Projects/Semantic_SBERT/speech_to_text_automated.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     config\u001b[39m=\u001b[39;49mconfig_wav_enhanced,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Python%20Projects/Semantic_SBERT/speech_to_text_automated.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     audio\u001b[39m=\u001b[39;49mlong_audi_wav\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Python%20Projects/Semantic_SBERT/speech_to_text_automated.ipynb#W2sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Python%20Projects/Semantic_SBERT/speech_to_text_automated.ipynb#W2sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m response \u001b[39m=\u001b[39m operation\u001b[39m.\u001b[39mresult(timeout\u001b[39m=\u001b[39m\u001b[39m480\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Python%20Projects/Semantic_SBERT/speech_to_text_automated.ipynb#W2sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m Number_words \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\chang\\anaconda3\\envs\\Semantic_SBERT2\\lib\\site-packages\\google\\cloud\\speech_v1\\services\\speech\\client.py:684\u001b[0m, in \u001b[0;36mSpeechClient.long_running_recognize\u001b[1;34m(self, request, config, audio, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    681\u001b[0m rpc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport\u001b[39m.\u001b[39m_wrapped_methods[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport\u001b[39m.\u001b[39mlong_running_recognize]\n\u001b[0;32m    683\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 684\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[0;32m    685\u001b[0m     request,\n\u001b[0;32m    686\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[0;32m    687\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    688\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[0;32m    689\u001b[0m )\n\u001b[0;32m    691\u001b[0m \u001b[39m# Wrap the response in an operation future.\u001b[39;00m\n\u001b[0;32m    692\u001b[0m response \u001b[39m=\u001b[39m operation\u001b[39m.\u001b[39mfrom_gapic(\n\u001b[0;32m    693\u001b[0m     response,\n\u001b[0;32m    694\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport\u001b[39m.\u001b[39moperations_client,\n\u001b[0;32m    695\u001b[0m     cloud_speech\u001b[39m.\u001b[39mLongRunningRecognizeResponse,\n\u001b[0;32m    696\u001b[0m     metadata_type\u001b[39m=\u001b[39mcloud_speech\u001b[39m.\u001b[39mLongRunningRecognizeMetadata,\n\u001b[0;32m    697\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\chang\\anaconda3\\envs\\Semantic_SBERT2\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:154\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     metadata\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata)\n\u001b[0;32m    152\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m metadata\n\u001b[1;32m--> 154\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chang\\anaconda3\\envs\\Semantic_SBERT2\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:52\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     51\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m---> 52\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: 400 Invalid recognition 'config': bad encoding.."
     ]
    }
   ],
   "source": [
    "for n in range(8,22):\n",
    "    convert(f\"00{n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Semantic_SBERT2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97aa44590fedb5598f039a6e0531b8b2c1bd721b4f28d7d2659aa58c3efe1ec9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
