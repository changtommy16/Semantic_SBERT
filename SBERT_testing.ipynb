{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chang\\anaconda3\\envs\\semantic\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from torch import embedding\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet \n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12118967\n"
     ]
    }
   ],
   "source": [
    "def get_cosine_similarity(feature_vec_1, feature_vec_2):    \n",
    "    return cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0]\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings1 = model.encode(\"dog airplane is back time\", convert_to_tensor=True)\n",
    "#print(all_sentences001[i])\n",
    "embeddings2 = model.encode(\"I math earth run yesterday\", convert_to_tensor=True)\n",
    "#print(all_sentences001[i+1])\n",
    "#Compute cosine-similarities\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "#print(cosine_scores)\n",
    "# convert from PyTorch tensor to numpy array\n",
    "print(get_cosine_similarity(embeddings1, embeddings2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random words with random topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11874889\n"
     ]
    }
   ],
   "source": [
    "embeddings1 = model.encode(\"I math earth run yesterday\", convert_to_tensor=True)\n",
    "embeddings2 = model.encode(\"apple is a kind of plant\", convert_to_tensor=True)\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "print(get_cosine_similarity(embeddings1, embeddings2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 constructed sentence with 2 radom topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08581503\n"
     ]
    }
   ],
   "source": [
    "embeddings1 = model.encode(\"I really like to eat salad\", convert_to_tensor=True)\n",
    "embeddings2 = model.encode(\"apple is a kind of plant\", convert_to_tensor=True)\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "print(get_cosine_similarity(embeddings1, embeddings2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 constructed sentence with 2 related topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37476027\n"
     ]
    }
   ],
   "source": [
    "embeddings1 = model.encode(\"I really like to eat salad\", convert_to_tensor=True)\n",
    "embeddings2 = model.encode(\"where do i buy vegetables\", convert_to_tensor=True)\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "print(get_cosine_similarity(embeddings1, embeddings2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random words with 2 related topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41055107\n"
     ]
    }
   ],
   "source": [
    "embeddings1 = model.encode(\"develops math science technology\", convert_to_tensor=True)\n",
    "embeddings2 = model.encode(\"new physics numbers advance\", convert_to_tensor=True)\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "print(get_cosine_similarity(embeddings1, embeddings2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48605564\n"
     ]
    }
   ],
   "source": [
    "embeddings1 = model.encode(\"develops math technology science \", convert_to_tensor=True)\n",
    "embeddings2 = model.encode(\"numbers advance new physics\", convert_to_tensor=True)\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "print(get_cosine_similarity(embeddings1, embeddings2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentence testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6074123\n"
     ]
    }
   ],
   "source": [
    "embeddings1 = model.encode(\"tax\", convert_to_tensor=True)\n",
    "embeddings2 = model.encode(\"income\", convert_to_tensor=True)\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "print(get_cosine_similarity(embeddings1, embeddings2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordnet Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "syns1 = wordnet.synsets(\"dog\")\n",
    "syns2 = wordnet.synsets(\"hound\")\n",
    "print(syns1[0].wup_similarity(syns2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "syns1 = wordnet.synsets(\"coffee\")\n",
    "syns2 = wordnet.synsets(\"tea\")\n",
    "print(syns1[0].wup_similarity(syns2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsatellite\n",
      "floribunda\n",
      "unmonogrammed\n",
      "embryotrophic\n",
      "tifter\n",
      "cantharellus\n",
      "exactly\n",
      "acer\n",
      "disintegrations\n",
      "illaenus\n"
     ]
    }
   ],
   "source": [
    "from random_word import RandomWords\n",
    "r = RandomWords()\n",
    "for i in range(10):\n",
    "    print(r.get_random_word())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('semantic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c54165d08fd550b20e5d70a45269718a12194b1a3ed2e8c4cf823acd6cf23912"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
